---
title: "Timeline of Keynotes"
---

# Damon Keynotes Timeline

## 2023
### Memory: The DaMoN Demon
Abstract: Memory technology limitations bedevil current computing systems and data management does not escape. As silicon scaling delivers ever faster compute, memory falls further behind exposing capacity, bandwidth, and power deficiencies in our systems. Seeing these issues, computer architects propose memory hierarchy changes only to find most applications shrink-wrapped to the current hierarchy and unable to change. Data management applications provide an innovation bright-spot with researchers and developers ready to co-optimize from application-to-hardware to deliver improved performance. Hierarchy improvements often matter here first. Sitting squarely at this confluence, DaMoN serves to engender such co-optimizations. With this in mind, we will set a memory technology baseline using memory silicon trends and constraints. Additionally, we will set a memory system baseline summarizing current system memory architectures and issues. Next, we will look at the undeniable influence AI is exerting on the hierarchy. Taking memory technology, systems, and applications together, we will speculate on memory hierarchy changes to expect – potentially creating opportunities for future data management applications. One such change is already visible in CXL-enabled memory hierarchies envisioned to deliver higher capacity and perhaps more. Finally, we will speculate further on system optimizations around memory that are the subject of current research, like memory sharing and near memory computing. Active audience engagement is encouraged, as the goal of this presentation is a maximally productive DaMoN focused on vanquishing the memory demon.

#### Frank Hady (Intel Fellow, Intel’s Office of the CTO Systems Architecture and Engineering Group)
Frank Hady is an Intel Fellow responsible for memory and storage hierarchy innovation within Intel’s Office of the CTO Systems Architecture and Engineering Group. He is a long-time system researcher happiest when delivering innovations that span hardware and software. Over Frank’s three-decade career, he has contributed to the creation, delivery, and proliferation of fundamental systems technologies. His current focuses include memory hierarchy advances, near memory compute systems pathfinding, and the optimization of storage for AI. Frank was a founding member of the team that delivered Intel® Optane™ technology and architected the first products. He helped Intel build a successful storage business, directing overall storage pathfinding and architecture, and architecting Intel’s first NVMe SSDs. His systems contributions include research foundational to Intel’s heterogeneous compute platforms and key I/O interfaces. In networking, he has delivered industry benchmarks and built a supercomputer network. He has held cross-Intel leadership roles for both I/O and memory architecture. Frank has authored or co-authored numerous published papers and patents, and presents often on memory and storage. Frank earned a BS and MS in Electrical Engineering from the University of Virginia, and Ph.D. in Electrical Engineering from the University of Maryland.

### Cost-Intelligent Data Analytics in the Cloud
Abstract: For decades, database research has focused on optimizing performance under a fixed amount of resources. As more and more database applications move to the public cloud, we argue that it is time to make cost a first-class citizen when solving database optimization problems. In this talk, I will introduce the concept of “cost intelligence” and then sketch the architecture of a cloud data warehouse designed toward this goal. The project is in its early stages, and we would appreciate your valuable feedback.

#### Huanchen Zhang, (Tsinghua University)
Huanchen Zhang is an Assistant Professor in the IIIS (Yao Class) at Tsinghua University. His research interest is in database management systems with particular interests in indexing, data compression, and cloud databases. He received his Ph.D. degree from the Computer Science Department at Carnegie Mellon University. Before joining Tsinghua, he worked at Snowflake as a Postdoctoral Research Fellow. He is the recipient of the SIGMOD Jim Gray Dissertation Award (2021) and the SIGMOD Best Paper Award (2018).

## 2022
### In Computer Architecture, We Don't Change the Questions, We Change the Answers

When I was a new professor in the late 1980s, my senior colleague Jim Goodman told me, "On the computer architecture PhD qualifying exam, we don't change the questions, we only change the answers." More generally, I now augment this to say, "In computer architecture, we don't change the questions, application and technology innovations change the answers, and it's our job to recognize those changes." Eternal questions this talk will sample are how best to do the following interacting factors: compute, memory, storage, interconnect/networking, security, power, cooling and one more. The talk will not provide the answers but leave that as an audience exercise. I will dive a little more into compute and memory as in-progress trends provide both challenges and opportunities for creating tremendous value from (large) data.

#### Mark D. Hill (Microsoft Azure and University of Wisconsin-Madison)
Mark D. Hill is Partner Hardware Architect with Microsoft Azure (2020-present) where he leads software-hardware pathfinding. He is also the Gene M. Amdahl and John P. Morgridge Professor Emeritus of Computer Sciences at the University of Wisconsin-Madison (https://www.cs.wisc.edu/~markhill/), following his 1988-2020 service in Computer Sciences and Electrical and Computer Engineering. His research interests include parallel-computer system design, memory system design, and computer simulation. Hill's work is highly collaborative with over 160 co-authors. He received the 2019 Eckert-Mauchly Award and is a fellow of AAAS, ACM, and IEEE. He served on the Computing Community Consortium (CCC) 2013-21 including as CCC Chair 2018-20, Computing Research Association (CRA) Board of Directors 2018-20, and Wisconsin Computer Sciences Department Chair 2014-2017. Hill has a PhD in computer science from the University of California, Berkeley.

### Accelerating Video Database Systems using Emerging Hardware Technologies 
Over the last decade, advances in deep learning have led to a resurgence of interest in automated analysis of videos at scale. This approach poses many challenges, ranging from the high computational overhead associated with deep learning models to the types of queries that the user may ask. In this talk, I will present EVA, an end-to-end video database system that we are developing at Georgia Tech, for tackling these challenges using novel query optimization and machine learning techniques. I will then discuss about opportunities for the community to help accelerate video database systems using their expertise in leveraging emerging hardware technologies.

#### Joy Arulraj (Georgia Institute of Technology)
Joy Arulraj is an Assistant Professor of Computer Science at the Georgia Institute of Technology. His research focuses on developing systems for efficiently and effortlessly querying video datasets by synthesizing techniques from data systems and machine learning. His research has been recognized with the IEEE TCDE Early Career Award (2022) and the ACM SIGMOD Jim Gray Doctoral Dissertation Award (2019). His group is supported by funding from the NSF, Cisco Research, Alibaba, Adobe, and Intel.

### What the Primacy of Economics Means for Hardware And Software
Using several historical examples, I will argue that both hardware and software is downstream from economics. Economics has been called "the dismal science" and harsh economic realities can prevent technological breakthroughs. At the same time, however, economic thinking can also help overcome seemingly inescapable tradeoffs that we face when building software systems. It may also be our only hope for managing the proliferation of complex heterogeneous hardware, in particular in the cloud.

#### Viktor Leis (Friedrich-Alexander-Universität Erlangen-Nürnberg)
Viktor Leis is a Professor for Data Management at Friedrich-Alexander University Erlangen-Nürnberg, Germany. His research revolves around designing high-performance data management systems and includes core database topics such as query processing, query optimization, index structures, and storage. Viktor received his doctoral degree in 2016 from the Technical University of Munich, where he worked on the main-memory database system HyPer. He is the recipient of the ACM SIGMOD dissertation award (2018), the IEEE TCDE Rising Star Award, and four best paper awards at ICDE and SIGMOD.

## 2021
### Introduction to the Arm Neoverse N and V series: Cloud-to-Edge Infrastructure SoCs
In this talk I will present the Neoverse IP roadmap, detailing some of the characteristics of our IPs that make them a great choice for developing high performance SoCs from power-constrained edge appliances all the way up to systems targeting HPC and cloud deployments. Additionally, this talk will touch upon the state of cloud and SW applications, and will provide some pointers to users that want to extract more performance and value from Arm Neoverse instances that are now easily accessible in various cloud environments.

#### Andrea Pellegrini  (Arm)
Andrea Pellegrini leads the performance and workloads team for the Infrastructure Line of Business at Arm. Andrea is based in Austin, TX, USA and joined Arm to work on Arm servers in 2016, after spending 3 years at Intel, where he was an architect for IO virtualization. Andrea obtained a PhD in computer architecture from the University of Michigan, Ann Arbor, and holds a Master and a Bachelors degree in computer engineering from the Universita' di Bologna, Italy.


### Extend, Not Just Accelerate!
The hardware in today's datacenters and clouds is changing at a dizzying pace. Heterogeneity, accelerators and disaggregated architectures are becoming commonplace and change the way we design and operate databases. It has never been so easy to add an accelerator to a database but, in this talk, I will make the case that there is an alternative approach to be considered. Instead of building yet another analytics accelerator, we should use specialized hardware to offer new functionality in databases; functionality that makes them more secure, private and reliable! By using specialized hardware, the cost of such new functionality could be hidden, making future databases just as fast as today's while offering added benefits.

#### Zsolt István  (IT University of Copenhagen)
Zsolt István is an Associate Professor at the IT University of Copenhagen. Before that,  he was an Assistant Research Professor at the IMDEA Software Institute in Madrid.  Zsolt works in the intersection of databases, distributed systems, and FPGA programming. He has a PhD in Computer Science from the Systems Group at ETH Zurich, Switzerland.

### Cloud-native databases: opportunities and challenges
Organizations are moving their databases to the cloud due to lower cost, elastic resource allocation, availability, etc. Cloud brings unique opportunities and challenges that are unprecedented in conventional databases, which require us to revisit the software and hardware stacks of a DBMS to fully exploit the performance and cost potential. 
This talks focuses on a particular architectural feature of cloud-native databases — storage disaggregation, where computation and storage are independently managed and connected through the network. Disaggregation enables independent scaling of resources, but incurs long latency and bandwidth bottlenecks for IO since the storage is remote. I will share our recent papers (choosing cloud-DBMS [VLDB'19], pushdownDB [ICDE'20], and FlexPushdownDB [VLDB'21]) addressing these challenges. I will also share my thoughts on the potential research questions and solutions in this domain. 

#### Xiangyao Yu  (University of Wisconsin-Madison)
Xiangyao Yu is an Assistant Professor at the University of Wisconsin-Madison. His research interests include (1) transactions and HTAP, (2) new hardware for databases, and (3) cloud-native databases. Before joining UW-Madison, he finished his postdoc (2019) and PhD (2017) at MIT and his bachelor degree (2012) at Tsinghua University. 

## 2020
### A Vision for Expandable Data Management Infrastructure and Acceleration with Heterogenous Configurable Systems 
Coherently attached FPGAs will unlock the full potential of their configurable fabric by enabling expandable memory and bringing together the four components of a data management system – storage, memory, compute and network.  In this configuration, the CPU can access the memory or storage attached to the FPGA coherently, while the reconfigurable fabric is able to support look-aside and inline acceleration for CPU/storage, CPU/memory, CPU/network, network/storage paths. Computational storage as well as computational memory will be facilitated by the same fabric that resides at the core of the heterogeneous compute systems. In this talk, we will present a vision of how heterogenous compute systems centered around FPGAs can help with TCO, performance and power density and the use cases that support such vision. We will present device features of the UPI/CXL enabled FPGA and platforms that connects to DDR, persistent memory, persistent storage and high-speed networks. In addition to device and platform features, we will discuss how a software developer will be able to use such a platform using OneAPI.

#### José Roberto Alvarez, Senior Director CTO Office Lead, Intel Programmable Solution Group 
José Roberto Alvarez is Senior Director at Intel Programmable Solutions Group in San Jose, California, where he leads the Technology and Innovation CTO Office, defining and implementing long term FPGA research strategy and roadmaps. He started his career at Philips Laboratories and throughout his career he has been deeply engaged in architecting, designing and implementing technology products for a variety of industries including broadcast, embedded, consumer, post-production and computer graphics for companies including Philips, S3, Broadcom, Maxim, Xilinx, and four successful start-ups in Silicon Valley. His research interests include FPGA advanced architectures and development tools, immersive media technologies and volumetric coding. His work has been granted 53 patents.

## 2019
### Performance Scaling with Innovative Compute Architectures and FPGAs
Performance scaling and power efficiency with traditional computing architectures becomes increasingly challenging as next generation technology nodes provide diminishing performance and energy benefits. FPGAs with their reconfigurable circuits can tailor the hardware to the application through customized arithmetic and innovative compute and memory architectures, thereby exposing further potential for performance scaling. This has stimulated significant interest for their exploitation in compute intensive applications. During this talk, we discuss some examples of these innovative customized compute architectures in the context of data processing and show how these unleash new levels of performance scalability and compute efficiency.

#### Michaela Blott  (Xilinx Research)
Michaela Blott is a Distinguished Engineer at Xilinx Research, where she is heading a team of international scientists, driving research into new application domains for Xilinx devices, such as machine learning, in both embedded and hyperscale deployments.
She graduated from the University of Kaiserslautern in Germany and brings over 25 years of experience in computer architecture, FPGA and board design, working in both research institutions (ETH Zurich and Bell Labs) as well as development organizations.
She is strongly involved with the international research community as technical co-chair of FPL’2018, workshop organizer (H2RC), industry advisor on numerous EU projects, and serves on numerous technical program committees (FPL, ISFPGA, DATE, etc.)

### Dark silicon — a currency we do not control
The breakdown of dennard scaling changed the game of processor design:  no longer can the entire die be filled with "always-on" components -- some regions must be powered up and down at runtime to prevent the chip from overheating. Such "dim" or "dark" silicon is the new currency of chip design, raising the question: what functionality should be implemented in dark silicon? Viable candidates are any non-essential units that support important applications. Naturally, database researchers were quick to claim this resource, arguing that it should be used to implement instructions and primitives supporting database workloads.
In this talk, we argue that, due to economic constraints, such a design is unlikely to be implemented in mainstream server chips. Instead, chip designers will spend silicon on high-volume market segments such as AI, Security or Graphics/AR which require a different set of primitives. Consequently, database researchers need to find uses for the actual functionality of chips rather than wishing for features that are economically infeasible. Let us develop innovative ways to exploit the "hardware we have, not the hardware we wish to have at a later time". In the talk, we discuss examples of creative use of hardware for data management purposes such as TLBs for MVCC, Transactional Memory for statistics collection and hardware graphics shaders for data analytics. We also highlight some processor functionality that still calls for creative use such as many floating point instructions, integrated sound processors and some of the model-specific registers.

#### Holger Pirk  (Imperial College)
Holger Pirk is an assistant professor ("Lecturer" in traditional English terms) in the Department of Computing at Imperial College London. As such, he is a member of the Large-Scale Data and Systems Group.
He is interested in all things data: analytics, transactions, systems, algorithms, data structures, processing models and everything in between. While most of his work targets "traditional" relational databases, his declared goal is to broaden the applicability of data management techniques. This means targeting new platforms like GPUs or FPGAs but also new applications like compilers, games and AI.
Before joining Imperial, Holger was a Postdoc at the Database group at MIT CSAIL.  He spent his PhD years in the Database Architectures group at CWI in Amsterdam resulting in a PhD from the University of Amsterdam in 2015.

### Building real database systems on real persistent memory 
"Real" persistent memory, such as Intel Optane DC PMM, offers high density, persistence and speed in between flash and DRAM. This changes the way we deal with storage devices in database systems - it is byte-addressable like memory, yet it is also persistent. Systems researchers have been keen in exploring its use since more than 10 years ago, to build persistent indexes, new file systems, persistent queues, faster logging and better replication approaches. Yet almost all previous work had to be done in simulated environments. 
Now it is time to look back, rethink, and devise practical, innovative ways of exploiting real persistent memory in database systems. In this talk, we discuss our recent experience with real Optane DC PMMs and the implications and future roles of persistent memory in database systems. In particular, we highlight the challenges and issues that were not well understood in simulated environments, such as programming model and resource contention between DRAM and persistent memory. 

#### Tianzheng Wang  (Simon Fraser University)
Tianzheng Wang is an assistant professor in the School of Computing Science at Simon Fraser University in Canada (since Fall 2018). He works on the boundary between software and hardware to build better systems by fully utilizing the underlying hardware. His current research focuses on database systems and related systems areas that impact the design of database systems, such as operating systems, distributed systems, and synchronization. He is also interested in storage, mobile and embedded systems. Tianzheng Wang received his Ph.D. in computer science from the University of Toronto in 2017, advised by Ryan Johnson and Angela Demke Brown. Prior to joining Simon Fraser University, he spent one year (2017-2018) at Huawei Canada Research Centre (Toronto) as a research engineer. 

## 2018
### How Persistent Memory Changes the Server Environment 
New memory technologies bring with them an explosion in memory capacities, offering multiple terabytes per CPU socket. But more than that -- this new, large capacity memory is persistent! Andy will describe how this technology changes the server environment seen in data centers and clouds. He will explain the value of persistent memory, what it means to applications such as databases, and summarize what application vendors are doing to prepare for it. Andy will describe the work done by SNIA, the Storage Networking Industry Association, to align the industry on a unified programming model for persistent memory. He’ll show libraries and applications that have built on that model and describe the value they’ve demonstrated.

#### Andy Rudoff (Intel)
Andy Rudoff is a Senior Principal Engineer at Intel Corporation, focusing on Non-Volatile Memory programming. He is a contributor to the SNIA NVM Programming Technical Work Group. His more than 30 years industry experience includes design and development work in operating systems, file systems, networking, and fault management at companies large and small, including Sun Microsystems and VMware. Andy has taught various Operating Systems classes over the years and is a co-author of the popular UNIX Network Programming text book.

### Active Heterogeneous Hardware and its Impact on System Design 
The rise of hardware heterogeneity and the potential to offload compute closer to data (e.g., storage and memory) or to push operations down to where data moves (e.g., on the networks or acceleration within the chip) opens both exciting opportunities and significant challenges for system software like databases that want to make efficient use of future hardware. One of the main questions is then, who absorbs that complexity especially as we move to the "noisy" cloud?   In my talk, I will argue that addressing such a challenge requires an effort that is beyond what can be typically done within a single layer of the system stack. My proposal calls for a holistic approach by opening up the interfaces and customising the system stack for modern data processing workloads. 

#### Jana Giceva (Imperial College)
Jana Giceva is an assistant professor in the Department of Computing at Imperial College London, where she is part of the LSDS (Large Scale Data and Systems) group. Prior to that she completed her MSc and Phd in the Systems Group at ETH Zurich, where she was advised by Gustavo Alonso and co-advised by Timothy Roscoe. Her research interests are in systems support for Big Data and Data science to enable efficient use of modern and future hardware. The scope of her research spans multiple systems areas: from the data processing layer to operating systems, including hardware accelerators for data processing. She is the recipient of the ETH medal for her PhD dissertation awarded in 2017 and the Google European PhD Fellowship in operating systems in 2014.

### Scaling database systems to high-performance computers
Analyzing massive datasets quickly requires scaling foundational data processing algorithms to the unprecedented compute, network and I/O concurrency of a modern datacenter. However, the software building blocks that are readily available today have largely been designed for high-performance computing applications and are profoundly unsatisfactory for I/O-intensive analytics. This talk highlights specific research challenges that need to be overcome to scale data processing to warehouse-scale computers, with particular focus on how to better utilize RDMA-capable networks, non-uniform network topologies, massively parallel file systems and NVMe-based storage in a disaggregated datacenter.

#### Spyros Blanas (Ohio State)
Spyros Blanas is an assistant professor in the Department of Computer Science and Engineering at The Ohio State University. His research interest is high-performance database systems, and his current goal is to build a database system for high-end computing facilities. He has received the IEEE TCDE Rising Star Award and a Google Research Faculty award. He received his Ph.D. at the University of Wisconsin–Madison and part of his Ph.D. dissertation was commercialized in Microsoft's flagship data management product, SQL Server, as the Hekaton in-memory transaction processing engine.

### Designing Data Management Systems in the Age of Dark Silicon
Dennard scaling, which enables keeping the power density of the transistors constant, does not hold anymore. Even though we would be able to keep packing more cores in processors, we won’t be able to power all of them up simultaneously. This trend is referred to as dark silicon and fundamentally alters the focus of hardware design. In this new era, the focus needs to shift toward optimizing energy per instruction. This talk focuses on the implications of dark silicon and emerging hardware on the design of data management systems. 

#### Pinar Tözün (IT University of Copenhagen)
Pınar Tözün is an Associate Professor at IT University of Copenhagen. Before ITU, she was a research staff member at IBM Almaden Research Center. Prior to joining IBM, she received her PhD from EPFL. Her research focuses on HTAP engines, performance characterization of database workloads, and scalability and efficiency of data management systems on modern hardware. She received a Jim Gray Doctoral Dissertation Award Honorable Mention in 2016. 

## 2017
### HPC & AI

#### Dr. Eng Lim Goh (HPE)
Bio: Dr. Eng Lim Goh joined SGI in 1989, becoming a chief engineer in 1998 and then chief technology officer in 2000. After acquisition, HPE appointed him vice president and SGI chief technology officer. He oversees technical computing programs with the goal to develop the next generation computer architecture for the new many-core era. His current research interest is in the progression from data intensive computing to analytics, machine learning, artificial specific to general intelligence and autonomous systems. He continues his studies in human perception for user interfaces and virtual and augmented reality.
In 2005, InfoWorld named Dr. Goh one of the World’s 25 Most Influential CTOs. He was included twice in the HPCwire list of “People to Watch”; 2005 and 2015. In 2007, he was named “Champions 2.0" of the industry by BioIT World magazine, and received the HPC Community Recognition Award from HPCwire. Dr. Goh is a frequent industry speaker and he continues to discuss, in different forums, innovative technologies and their applications. He co-presented with NASA at the inaugural 1st plenary of the Supercomputing 2014 Conference to an audience of 2,500.
Before joining SGI, Dr. Goh worked for Intergraph Systems, Schlumberger Wireline and Shell Research. A Shell Cambridge University Scholar, Dr. Goh completed his Ph.D. research and dissertation on parallel architectures and computer graphics, and holds a first-class honors degree in mechanical engineering from Birmingham University in the U.K. Dr. Goh has been granted six U.S. patents.

### The Latest Advances in GPU Architectures and New Programming Model Features
GPU architectures are approaching a terabyte per second memory bandwidth that, coupled with high-throughput computational cores, creates an ideal device for data-intensive tasks. We'll discuss GPU accelerator fundamentals as well as the best practices when developing your applications for modern GPU architectures. Both the architecture and the programming model evolved over the past few years to help developers achieve high performance quicker and with less effort. New features, such as Unified Memory, have been introduced to simplify development on heterogeneous architectures and provide seamless processing of large out-of-core data workloads. New libraries, such as nvGraph, make it possible to build interactive and high throughput graph and data analytics applications. An overview of existing tools and libraries will be covered to help you get started with the GPU programming.

#### Nikolay Sakharnykh (Nvidia)
Nikolay Sakharnykh is a senior developer technology engineer at NVIDIA, where he works on accelerating HPC and data analytics applications on GPUs. He joined NVIDIA in 2008 as a graphics engineer working on making video games run faster and enabling new visual effects. At the same time, CUDA started to pick up, and he got excited about the general compute capabilities of the GPUs. After a few years his professional interests shifted towards more serious applications in HPC. Now he's exploring GPU applications for graph and data analytics and new memory management techniques.

## 2016
### Looking Beyond Exaflops and Zettabytes
We are seeing an unprecedented convergence of massive compute with massive data. This confluence has the potential to significantly impact how we do computing and what computing can do for us. In this talk I will discuss some of the application-level opportunities and system-level data management challenges at the intersection of traditional high-performance computing and emerging data-intensive computing.

#### Pradeep Dubey (Intel Labs)
Pradeep Dubey is an Intel Fellow and Director of Parallel Computing Lab (PCL), part of Intel Labs. His research focus is computer architectures to efficiently handle new compute- and data-intensive application paradigms for the future computing environment. Dubey previously worked at IBM's T.J. Watson Research Center, and Broadcom Corporation. He has made contributions to the design, architecture, and application-performance of various microprocessors, including IBM® Power PC*, Intel® i386TM, i486TM, Pentium® Xeon®, and the Xeon Phi™ line of processors. He holds over 36 patents, has published over 100 technical papers, won the Intel Achievement Award in 2012 for Breakthrough Parallel Computing Research, and was honored with Outstanding Electrical and Computer Engineer Award from Purdue University in 2014. Dr. Dubey received a PhD in electrical engineering from Purdue University. He is a Fellow of IEEE.

## 2015
### Rethinking Memory System Design for Data-Intensive Computing
The memory system is a fundamental performance and energy bottleneck in almost all computing systems. Recent system design, application, and technology trends that require more capacity, bandwidth, efficiency, and predictability out of the memory system make it an even more important system bottleneck. At the same time, DRAM and flash technologies are experiencing difficult technology scaling challenges that make the maintenance and enhancement of their capacity, energy-efficiency, and reliability significantly more costly with conventional techniques.
In this talk, we examine some promising research and design directions to overcome challenges posed by memory scaling. Specifically, we discuss three key solution directions: 1) enabling new memory architectures, functions, interfaces, and better integration of the memory and the rest of the system, 2) designing a memory system that intelligently employs multiple memory technologies and coordinates memory and storage management using non-volatile memory technologies, 3) providing predictable performance and QoS to applications sharing the memory/storage system. If time permits, we might also briefly touch upon our ongoing related work in combating scaling challenges of NAND flash memory.

#### Onur Mutlu (Carnegie Mellon University)
Onur Mutlu is the Strecker Early Career Professor at Carnegie Mellon University. His broader research interests are in computer architecture and systems, especially in the interactions between languages, system software, compilers, and microarchitecture, with a major current focus on memory systems. He obtained his PhD and MS in ECE from the University of Texas at Austin and BS degrees in Computer Engineering and Psychology from the University of Michigan, Ann Arbor. Prior to Carnegie Mellon, he worked at Microsoft Research, Intel Corporation, and Advanced Micro Devices. He was a recipient of the IEEE Computer Society Young Computer Architect Award, Intel Early Career Faculty Award, faculty partnership awards from various companies, including Facebook, Google, HP, Intel, IBM, Microsoft and Samsung, a number of best paper recognitions at various computer systems venues, and a number of "computer architecture top pick" paper selections by the IEEE Micro magazine. For more information, please see his webpage.

## 2014
### The Picosecond is Dead; Long Live the Picojoule
For decades, CMOS technology provided exponential improvements in transistor density and energy consumption, allowing hardware architects to focus on removing picoseconds from processor clock cycles and adding megabytes to on-chip caches. Unfortunately, we are now in a phase where transistor cost and energy consumption are barely scaling. Consequently, the new name of the game is accounting for and optimizing every picojoule the hardware consumes. This talk will describe the challenges and opportunities in designing high performance, yet energy efficient systems. Specifically, we will discuss hardware and software specialization, memory systems for data intensive applications, and raising utilization in cloud deployments. While these approaches represent a non-trivial departure from the way we design and use systems today, combined they can provide improvements equivalent to a few decades of Moore's law scaling.

#### Christos Kozyrakis (Stanford University)
Christos Kozyrakis is an Associate Professor of Electrical Engineering & Computer Science at Stanford University. He works on architecture, runtime management, system software, and programming models for systems ranging from cellphones to warehouse-scale datacenters. His past research includes energy-efficient data-parallel architectures, transactional memory technology, and practical hardware support for robust security abstractions. He is currently working on hardware and software techniques for resource efficient cloud computing. Christos received a BS degree from the University of Crete (Greece) and a PhD degree from the University of California at Berkeley (USA), both in Computer Science. He is a senior member of the ACM and the IEEE.

## 2013
### Netezza Performance Architecture
#### Daniel J. "Dan" Feldman (Netezza)

## 2012
### Redrawing the Boundary Between So3ware and Storage for Fast Non-Volatile Memories 
#### Steven Swanson (UCSD)

## 2011
### The coming revolution in data-centric data centers
We are entering an exciting era for systems design. Digital information is increasing at exponential rates and new applications are being developed to extract fresh insights from all this data. At the same time, we are seeing interesting inflection points in technology - faster, more complex, processors are being replaced by simpler, power-efficient multicores; traditional memory and storage technologies are being challenged by new non-volatile memories like phase-change RAM and Memristors; optics is replacing electrical communications. Consequently, traditional approaches to design "better, faster, cheaper" systems will need to be (and are being) rethought, both at the hardware and software levels. In this talk, I will discuss these recent trends, their implications for future hardware re-designs, and the immense opportunities ahead for new solutions that cross-cut the technology, architecture, and software layers.

#### Parthasarathy Ranganathan (HP Labs)
Partha Ranganathan is a distinguished technologist at Hewlett Packard Labs where he currently leads a research program on future data-centric data centers. His research interests are in energy efficiency and systems architecture and modeling. He has worked extensively in these areas including key contributions around energy-aware user interfaces, heterogeneous multi-core processors, power capping and federated enterprise power management, energy modeling and benchmarking, disaggregated blade server architectures, and most recently, storage hierarchy and systems redesign for non-volatile memory. Dr. Ranganathan's work has led to several commercial products and has been featured in the New York Times, Wall Street Journal, Slashdot, and several other venues. He was named one of the world's top young innovators by MIT Technology Review, and has received Rice University's Outstanding Young Engineering Alumni award. Dr. Ranganathan received his B.Tech degree from the Indian Institute of Technology, Madras and his M.S. and Ph.D. from Rice University, Houston.

## 2010
### Trends in Storage Technologies
This presentation highlights some of the leading-edge topics in storage technology research today. The main focus will be online storage and specifically solid-state-based storage-class memory (SCM), which has the potential of revolutionizing architectures for data storage. In this context, we will review the application of Flash to enterprise storage and discuss high-potential follow-on technologies in this space and their implications for the memory/storage hierarchy. Moreover, we will also look at the other extreme, namely storage technologies for archival data, and discuss how the explosive growth of such data and the subsequent ultra-high capacity requirements affect the incumbent technologies such as magnetic tape and optical archives. Finally, we'll touch upon the impact of these disruptive technologies on the tiered storage.

#### Dr. Evangelos Eleftheriou (IBM Fellow, IBM Zurich Lab)
Dr. Eleftheriou received a B.S. degree in electrical engineering from the University of Patras, Patras, Greece, in 1979, and the M.Eng. and Ph.D. degrees in electrical engineering from Carleton University, Ottawa, Canada, in 1981 and 1985, respectively. In 1986, he joined IBM Research. Zurich, where he currently manages the Storage Technologies Department, which focuses on phase-change memories, scanning-probe techniques and metrology, solid-state drive technology and systems as well as tape drive technology. In January 2002 Dr. Eleftheriou was elected Fellow of the IEEE. He was co-recipient of the 2003 IEEE Leonard G. Abraham Prize Paper Award and co-recipient of the Eduard Rhein Technology Award in 2005. The same year, he became an IBM Fellow and was inducted into the IBM Academy of Technology. In 2009 he was co-recipient of the IEEE Transactions on Control Systems Technology Outstanding Paper Award and the IEEE Control Systems Technology Award

## 2009
### Sweet Sixteen: How well is Transactional Memory Aging?
The term ``Transactional Memory'' was coined back in 1993, but even today, there is a vigorous debate about its merits. This debate sometimes generates more heat than light: terms are not always well-defined and criteria for making judgments are not always clear.
In this talk, I will try to impose some order on the conversation. TM itself can encompass hardware, software, speculative lock elision, and other mechanisms. The benefits sought encompass simpler implementations of highly-concurrent data structures, better software engineering for concurrent platforms, enhanced performance, and reduced power consumption. We will look at various terms in this cross-product and evaluate how we are doing. So far.

#### Maurice Herlihy (Brown University)

## 2008
### Amorphous Data Parallelism
Client-side applications running on multicore processors are likely to be irregular programs that deal with complex, pointer-based data structures such as graphs and trees.  In her 2007 Turing award lecture, Fran Allen raised an important question about such programs: do irregular programs have data parallelism, and if so, how do we exploit it on multicore processors?
In this talk, we argue using concrete examples that irregular programs have an amorphous data-parallelism that arises from the use of iterative algorithms that manipulate worklists of various sorts. We then describe the approach taken in the Galois project to exploit this parallelism.  There are three main aspects to the Galois system: (1) a small number of syntactic constructs for packaging amorphous data-parallelism as iterations over ordered and unordered sets, (2) assertions about methods in class libraries, and (3) a runtime system for managing the exploitation of amorphous data-parallelism.  We present experimental results that demonstrate that the Galois approach is practical, and discuss ongoing work on this system.

#### Keshav Pingali (University of Texas, Austin)
Keshav Pingali is the W.A."Tex" Moncrief Chair of Computing in the Computer Sciences department at the University of Texas, Austin. He received the B.Tech. degree in Electrical Engineering from IIT, Kanpur, India in 1978, the S.M. and E.E. degrees from MIT in 1983, and the Sc.D. degree from MIT in 1986.  He was on the faculty of the Department of Computer Science at Cornell University from 1986 to 2006, where he held the India Chair of Computer Science.
Pingali's research has focused on programming languages and compiler technology for program understanding, restructuring, and optimization.  His group is known for its contributions to memory-hierarchy optimization; some of these have been patented. Algorithms and tools developed by his projects are used in many commercial products such as Intel's IA-64 compiler, SGI's MIPSPro compiler, and HP's PA-RISC compiler.  In his current research, he is investigating optimistic parallelization techniques for multicore processors, and language-based fault tolerance.
Among other awards, Pingali has won the President's Gold Medal at I.I.T.  Kanpur (1978), IBM Faculty Development Award (1986-88), NSF Presidential Young Investigator Award (1989-94), Ip-Lee Teaching Award of the College of Engineering at Cornell (1997), and the Russell teaching award of the College of Arts and Sciences at Cornell (1998). In 2000, he was a visiting professor at I.I.T., Kanpur where he held the Rama Rao Chaired Professorship.  Since 2007, he has been the co-Editor-in-chief of the ACM Transactions on Programming Languages and Systems (TOPLAS).

## 2007
### Information Management and System/Storage Technology — Evolution or Revolution?
The role and design of systems responsible for the management of information in the enterprise is changing. The kind of information that is being managed is changing as is the way the information is analyzed and made available to users in the enterprise. At the same time system and processor technology is undergoing what some consider a fundamental shift as processor designers grapple with the power/heat issues associated with ever higher frequencies. In this talk we will review the forces that are influencing both the software and the hardware systems.

#### Berni Schiefer (IBM Toronto)
Berni Schiefer is a DB2 Distinguished Engineer at IBM. He has responsibility for DB2 performance benchmarking and solutions development, including the BCU. He joined the IBM Toronto Lab in 1985 and has worked on SQL/DS and the Starburst experimental relational database at the IBM Almaden Research Lab, prior to working on DB2. His current focus is on introducing advanced technology into DB2 with particular emphasis on processors, performance, XML, Linux, Virtualization and Autonomics. 

## 2006
### Data Management Challenges on New Computer Architectures
#### Doug Carmean (Intel)